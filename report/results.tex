\section{Results} \label{results}

lorem ipsum ...

\subsection{DWT, feature extraction strategy}
Explain typycal approach, and why using DWT and then epoching is advantageaous while remaing fast.


\subsection{\texttt{Python} package}
Several algorithms to extract features from univariate time series had already been implemented in the \py{} package \pyeeg{}\citationneeded{}.
Unfortunately, some of them were critically slow, and could not realistically have been used in the present study.
Preliminary investigation of the source code revealed that runtimes may be improved by vectorising expressions and pre-allocating of temporary arrays.
Therefore, systematic reimplementation of all algorithms in \pyeeg{} was undertaken.
Very significant improvement in performance and scalability were achieved (table~\ref{tab:benchmark}).

Importantly, several mathematical inconsistancies between the original code and the mathematical definitions were also noticed.
This affected five of the eight reimplemented functions(table~\ref{tab:benchmark}). 
Detail of the corrections performed are provided, as notes, in the documentation of the new package\TODO{ref appendix}.
Numerical results for the three remaining functions were consitstant throughout optimisation.

In order to facilitate feature extrcation, several data structures and routines were also implemented 
in a new python package named \pr{}.
Briefly, extentions of \texttt{numpy} arrays providing metadata, sampling frequency, and other attributes were used to represent time series. 
User friendly indexing with string representing time was also developed.
In addition, a container for time series of discrete anotation levels, each linked to a confidence level, was built.
Importantly, a container for multiple time series, which supports different sampling frequencies
between time series was implemented.
The new package also provides visualisation, input/output, and wrappers for resampling and discrete wavelet decomposition.
Finally, unittests were implemented to ensure presistance of mathematical and programmatic validity though-out developmental stage.
A full documentation of \pr{} is provided in the appendix\TODO{ref} of the report herein.


\input{./tables/benchmark}


Interface imporvement (see package doc)

Visualisation (explain why it is important)


\subsection{Important features}
$n$ is large, reducing $p$ could make the analysis faster. computing each $p$ feature is slow.
variable importance can be used to select a subset of informative variable.

20ish variable are good enough.

The analysis can be rendered faster
\subsection{Including temporal information}
Using features at $\mathbf{Z} = \{\mathbf{X_{t-\tau}}, ..., \mathbf{X_{t}}, ..., \mathbf{X_{t+\tau}}\}$ provide a significant improvement over $\mathbf{Z} = \mathbf{X_{t}}$.


\subsection{Confidence assesments}
For a classification algorithm, it is interesting to be able to provide a assotiate a confidence value to a prediction.
It is possible to interpret prediction by ensemble learning methods in a probabilistic context.
An entropy based value of confidence $c$ was defined as:
\begin{equation}
%~ \[
c = 1 + \frac{1}{log_2(|v|)}\sum{v_i  log_2(v_i)}
%~ \]
\end{equation}
where $v_i$ is the proportion of votes for the class $i$.
This definition has the property $c \in [0;1]$.
In order to study the relationship between $c$ and the probability of error,
the average cross-validation error was computed for different degrees of confidence (fig\ref{fig:error}A).
As expected, the probability of misclassification decreases monotonicaly with $c$.

The distibution of confidence levels(\ref{fig:error}B) shows that high confidences are more frequent... 

%~ 
%~ 
%~ It does not seem adventageous to use $\tau > 3$.
\subsection{Prediction results}

In order to assess the predictor in a ...

As oposed to previous results, the final random forests were trained, and tested, with sub-samples accounting for the respective biological prevalence of the three stages (\ie{} unbalanced).
Only the top N\TODO{} important variables \TODO{ref table}, were used. Temporal information was included using eq.\ref{eq:lag}\TODO{ref}.



